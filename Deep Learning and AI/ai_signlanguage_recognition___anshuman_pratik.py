# -*- coding: utf-8 -*-
"""AI_SignLanguage_Recognition | Anshuman Pratik.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cOArLgppKDnF_z8oeAQQidlVB3Nf1JAN

**ANSHUMAN PRATIK**

**'Artificial Intelligence Sign Language Recognition'**

*Edunet Foundation & IBM SkillsBuild Internship*
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing essential libraries for Data visualization
import pandas as pd
import numpy as np
import keras
import cv2 
from keras.models import Sequential 
from keras.layers import Conv2D,MaxPooling2D, Dense,Flatten
from keras.datasets import mnist 
import random as rd
import os
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import plotly.express as px
from PIL import Image
from keras.utils import np_utils
from keras.optimizers import SGD

"""# New section"""

#Libraries for Image processing
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
from keras.preprocessing.image import ImageDataGenerator

#Initializing reproducibility of seed by TensorFlow
from numpy.random import seed
seed(10)
tf.random.set_seed(20)

#Joining path of Kaggle File to Directory
for dirname, _, filenames in os.walk('/kaggle/input'):
  for filename in filenames:
    print(os.path.join(dirname, filename))

#Accessing Training and Testing data from Google Drive
train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sign_mnist_train.csv')
test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sign_mnist_test.csv')

train_data.head()

test_data.head()

#Computing Null Value in each column Data set after Preprocessing
print("Null values in Each column in Training data set = ",sum(train_data.isnull().sum()))
print("Null values in Each column in Testing data set = ", sum(test_data.isnull().sum()))

#Creating data labels for training and testing sets
y_train = train_data["label"]
x_train = train_data.drop(labels = ["label"],axis=1)
y_test = test_data["label"]
x_test = test_data.drop(labels = ["label"],axis=1)

#Converting pixel range to 0-1 from initial 0-255
x_train = x_train /255.0
x_test = x_test /255.0
#Making number of elements in set same when reshaped
x_train = x_train.values.reshape(-1,28,28,1) 
x_test = x_test.values.reshape(-1,28,28,1)
print(x_train.shape)
print(x_test.shape)

#Interactive Bar graph showing distribution of Labels count in training set
bar_graph= px.histogram(train_data, x='label', color='label', title='Distribution of Labels in Training Set') 
bar_graph.show()

#Interactive Bar graph showing distribution of Labels count in testing set
bar_graph_test= px.histogram(test_data, x='label', color='label', title='Distribution of Labels in Testing Set') 
bar_graph_test.show()

#Creating 5 x 5 Grid of  25 Training images
fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 10), subplot_kw={'xticks': [], 'yticks': []})
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.imshow(np.squeeze(x_train[i]), cmap ='gray')
  plt.title(y_train[i])
plt.show()

#Testing new images on Model
fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 10), subplot_kw={'xticks': [], 'yticks': []})
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.imshow(np.squeeze(x_test[i]), cmap ='gray')
  plt.title(y_test[i])
plt.show()

#Splitting of training images for modeling and validation of sign images.
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=104, shuffle=True)
print(x_train.shape)
print(y_train.shape)

print(x_val.shape)
print(y_val.shape)

print(x_test.shape)
print(y_test.shape)

#Modellig Rectified Linear Unit Convolution Neural Networks
model = keras.Sequential([
                          layers.BatchNormalization(),
                          layers.Conv2D(filters=32, kernel_size=(5,5), activation="relu", padding ='same', input_shape=[28,28,1]),
                          layers.MaxPool2D(),
                          layers.Dropout(.25),

                          layers.BatchNormalization(),
                          layers.Conv2D(filters=32, kernel_size=(3,3), activation="relu", padding ='same'),
                          layers.MaxPool2D(),
                          layers.Dropout(.25),

                          layers.BatchNormalization(),
                          layers.Conv2D(filters=64, kernel_size=(3,3), activation="relu", padding ='same'),
                          layers.MaxPool2D(),
                          layers.Dropout(.25),

                          layers.BatchNormalization(),
                          layers.Conv2D(filters=128, kernel_size=(3,3), activation="relu", padding ='same'),
                          layers.MaxPool2D(),
                          layers.Dropout(.25),

                          layers.Flatten(),
                          layers.Dropout(0.25),
                          layers.Dense(units=64, activation="relu"),
                          layers.Dense(units=26, activation="softmax"),
                           ])

#Compilation of CNN Model
model.compile(
    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),
    loss= 'sparse_categorical_crossentropy',
    metrics =['accuracy']
)

#Tarining model against Epoch and Batch Size
history = model.fit(
    x=x_train,
    y=y_train,
    validation_data=(x_val,y_val),
    batch_size=128,
    epochs=50,
    verbose=2
)

#Obtaining Training Data Frame
history_frame = pd.DataFrame(history.history)
history_frame.loc[:, ['loss', 'val_loss']].plot()
history_frame.loc[:, ['accuracy','val_accuracy']].plot()

#Estimation of prediction using Test pixels
pred = model.predict(x_test)
prediction = np.argmax(pred,axis=1)

#Prediction final report describing Precision, Recall and F1-Score of 25 Images
print(classification_report(y_test,prediction))

"""# **Reference Link:** https://colab.research.google.com/drive/1cOArLgppKDnF_z8oeAQQidlVB3Nf1JAN#scrollTo=T9E_b1srgnkZ"""